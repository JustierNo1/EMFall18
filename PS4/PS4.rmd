---
title: "Problem Set 4 Empirical Methods"
author: "Patrick Glettig (13-252-143), Carmine Ragone (14-995-021)"
date: "16.12.2018"
output:
  html_document:
    df_print: paged
  pdf_document:
    extra_dependencies: dcolumn
---

```{r global options, include=FALSE}
library(knitr)
library(Cairo)
library(extrafont)
library(latex2exp)
library(readstata13)
library(Hmisc)
library(lmtest)
library(stargazer)
library(kableExtra)
library(ggplot2)
library(data.table)
library(tidyr)
library(formatR)
library(dplyr)
library(car)
library(sjmisc)
library(plm)


#install.packages("pacman")
#pacman::p_load(knitr, Cairo, extrafont,latex2exp,readstata13,Hmisc,lmtest,stargazer,kableExtra,ggplot2,data.table,tidyr,formatR,dplyr,car,sjmisc,plm) 


knitr::opts_chunk$set(echo = TRUE, warning = FALSE,fig.show = "hold", collapse = TRUE, tidy.opts=list(width.cutoff=60),tidy=TRUE)

sysinf <- Sys.info()
if(sysinf['sysname'] == "Windows"){
  extrafont::loadfonts(device="win")
  #opts_chunk$set(dev = "CairoPDF")
}
```


# Paper and Pencil Questions

## Motivating Linear Panel Data

### (a)

First follow the hint and write down the function in level terms:
\begin{align*}
y_{it} &= x_{it}\beta+\alpha_i+\epsilon_{it} \\
\log{y_{it}}&=\log{x_{it}}\beta+\log{\alpha_i}+\epsilon_{it} \\
e^{\log{y_{it}}}&=e^{\log{x_{it}}\beta+\log{\alpha_i}+\epsilon_{it}} \\
y_{it} &= x_{it}^{\beta} \alpha_{i} e^{\epsilon_{it}}
\end{align*}

The farmer will maximize his profit by changing the input factor $x_{it}$, therefore he maximizes his expected profit function with respect to $x_{it}$. We first find the profit function

\begin{align*}
\pi(x_{it},\alpha_{i})&=P_t(y_{it})-W_t(x_{it}) \\
&=P_t (x_{it}^{\beta} \alpha_{i} e^{\epsilon_{it}}) - W_t x_{it}
\end{align*}

To find the expected profit function, we use the hint $\lambda=Ee^{\epsilon_{it}}$:
\begin{align*}
E(y_{it}|x_{it}) &= E(x_{it}^{\beta} \alpha_i e^{\epsilon_{it}})
&= x_{it}^{\beta} \alpha_i E(e^{\epsilon_{it}}) \\
&= x_{it}^{\beta} \alpha_i \lambda
\end{align*}

Now maximize the profit function using the hint above:

\begin{align*}
\max{E(\pi_{it}|x_{it}) &= E(P_t y_{it} - W_t x_{it} | x_{it})} \\
&= P_t (x_{it}^{\beta} \alpha_{i} \lambda) - W_t x_{it}
\end{align*}

\begin{align*}
\frac{\partial \pi_{it}}{\partial x_{it}}= \beta P_t x_{it}^{\beta-1} \alpha_i \lambda - W_t &{\overset{!}{=}} 0 \tag{F.O.C.} \\
x_{it}^{\beta-1} &= \frac{W_t}{\beta P_t \alpha_i \lambda} \\
x_{it} &= \left(\frac{\beta P_t \alpha_i \lambda}{W_t}\right)^{\beta-1}
\end{align*}


The labor demand $x_{it}$ depends on wages $W_t$, the labor demand coefficient $\beta$, prices $P_t$, soil quality $\alpha_i$ and rainfall $\epsilon_{it}$.

**Economic intuition:**
If prices are rising, farmers should produce more (this also aligns with any basic supply function). When wages rise, the optimal output will be less. The better the soil quality and rainfall, the more working hours are required (note that here the interpretation depends on how these variables are measured). It is worth to mention that, if $\epsilon_{it} \sim N(0,1)$ then $E(\epsilon_{it})=0$ and $\lambda=1$, so rainfall in expectation does not affect labor demand.  Nevertheless we assume that $\beta$ is some kind of input-output elasticity, a factor by how much $labor$ is turned into $output$. If this factor increases, it pays for the farmer to demand more working hours.

$\beta$ is an input-output elasticity, a factor by how much $labor$ is turned into $output$. Generally in labor economics, $\beta \in (0,1)$. If we assume this is the case, the lower $beta$, the more $labor$ is demanded. This makes sense as with a low elasticity, more workers are needed to achieve the same output. If $\beta=1$, $x_{it}=1$ and if $\beta>1$, $W_t$ becomes the numerator divided by $\beta P_t \alpha_i \lambda$ while the whole fraction is taken to the power of some positive number. Which means that the whole interpretation described in the paragraph above turns around (e.g. increase becomes decrease). Again, this makes sense in an economic way as in such a case with one unit of $labor$, more than one unit of $output$ is produced.

### (b)

Any OLS-equation is required to be linear to recover a consistent estimate. However, production functions can hardly assumed to be linear. In the given example, the farmer chooses $x_{it}$ by a non-linear expression of $\beta,P_t, \alpha_i$ and $\lambda$. Therefore, it is likely that the assumption of linearity is violated in the case at hand.

# Empirical Applications

## IV Regression

```{r results='hide'}
BCHHS <- fread('BCHHS.csv')
head(BCHHS) # Check the format
BCHHS$lnearn <- log(BCHHS$earning) #create log earnings
BCHHS$agesq <- (BCHHS$age)^2 #create age squared
dim(BCHHS) #Check length
summary(BCHHS) #Explore the data
```

### a)

```{r, message=FALSE, warning=FALSE, results='asis'}
Model1 = lnearn ~ highqua + age + agesq
Model2 = lnearn ~ twihigh + age + agesq

lm1 <- lm(Model1, data = BCHHS, x=TRUE)
lm2 <- lm(Model2, data = BCHHS, x=TRUE)
```
```{r tab1, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
stargazer(lm1, lm2, title="Regression Results Earnings with and without IV", type="latex", header = FALSE,
 align=TRUE, dep.var.labels=c("Log Wage"),
 covariate.labels=c("Education", "Education Instrument", "Age", "Age squared"),
 no.space=TRUE)
```

i)
Yes, the only estimate which is identical is the coefficient on education. The discrepancy however is not serious because the estimates confirm the paper's results; an increase in education (also in the education instrument) increases earnings, an increase in age goes along with an increase in earnings and an increase in age squared causes a decrease in earnings. All estimates are still significant, pointing to a causal effect. The results also match the pattern of other research mentioned in the paper. Therefore, this discrepancy is not serious.

ii)
The constant could be interpreted as average log earnings when everything else is zero, in other words the average log earnings of newborns with zero education. Since this does not really make sense, there is no important information contained in that coefficient.

iii)
*First Model:* A one year increase in education increases earnings by approximately 7.7% (or technically, by $100(e^{\beta_2}-1)\%$, `r 100*(exp(lm1$coefficients[2])-1)`%. A one year increase in age increases earnings by approximately 7.8%. However, age has a decreasing marginal effect showed in age squared: a one-unit increase in age squared decreases earnings by approximately 0.1%. The turning point of age can be found by $-\frac{\beta_3}{2\beta_4}=40.21$, after this age the effect of age on earnings becomes negative.

*Second Model:* The interpretation is the same as for the first model (with slightly different numbers), only that instead of actual education, an instrumental variable is used: a one year increase in reported education increases earnings by approximately 5.5%. The turning point is approximately half a year earlier, at 39.6 years.

### b)

i)
- Measurement Error: As the authors of the study mention on page 3, 10% of variation in schooling is due to measurement   error. This especially becomes important with the fact that the measure is self-reported.
- Omitted Variable Bias: the model wants to estimate the effect of schooling on income. However, without controls years of education could simply be a proxy for ability, as more intelligent individuals attend university and therefore have more years of education.

ii)
- Measurement Error: assuming that we have a classical measurement error, this would result in an attenuation bias of the independent variable, i.e. a positive bias (the coefficient is larger than it actually is)

- OVB: Ability is likely to be positively correlated with earnings since higher skilled individuals can take more demanding jobs (hence earn more). Education will also be positively correlated with ability (see reasoning above). Therefore, the sign of the bias is positive.

## Basic Panel Data Methods

```{r results='hide'}
Gasoline <- fread('Gasoline.csv')
head(Gasoline) # Check the format
dim(Gasoline) #Check length
summary(Gasoline) #Explore the data
```

### (a)
$ln\left(\dfrac{Gas}{Car}\right)_{it}$ is the gasoline consume per car in the 18 OECD countries over the 19 years. The variables $ln\left(\dfrac{Y}{N}\right)_{it}$  (per capita income) and $ln\left(\dfrac{P_{MG}}{P_{GDP}}\right)_{it}$ (gasoline price) are relevant because they reflect the utilization of autos. In specific, countries with an higher per capita incame use the car more because they can afford to own a car and to use it often. On the other hand, in countries with lower income per capita people will prefer to use the cheaper transportation means when possible. Thus, a positive sign is expected for this variable.[^1] The last variable $ln\left(\dfrac{Car}{N}\right)_{it}$ captures the stock of cars per capita. The rising stock of cars per capita is likely to lead to reduced auto utilization. This is pretta intuitive: (using the same example of the autors of the paper) the two-car family does not drive twice the miles of a one-car family.

[^1]:However, it might be possible to have a negative sign. Assuming that countries with an higher income pro capita have better public transport and more urbanized city centers -e.g Switzerland- people will be more willing to use more public transportations or bike to avoid traffic jam. Thus, the gasoline consume decreases with the increase with the increase of income per capita. 

### (b)
```{r results='hide'}
Gasoline <- fread('Gasoline.csv')
#Y <- cbind(c,data=Gasoline)
#X <- cbind(y,p,car,data=Gasoline)

# Set data as panel data
pdata <- pdata.frame(Gasoline, index=c("co","year"))

# Pooled OLS estimator
pooling <- plm(c ~ y+p+car, data=pdata, model= "pooling")

```
```{r}
stargazer(pooling, type="text", title="Pooled OLS Results",
          dep.var.labels=c("Gas per car consumption"),
          covariate.labels=c("Per capita income", "Gasoline price","Cars per capita"), align=TRUE)
```
### (c)
The estimating equation for a general Pooled OLS is $y_{it} = x'_{it} \beta + \alpha_{i} + \upsilon_{it}$ where the dummy variables $d_{t}$ are included into $x_{it}$ and the error term is $\upsilon_{it} =\alpha_{i} + \epsilon_{it}$ . This means that we are ignoring the unobserved heterogeneity $\alpha_{i}$ - which representes some individual caracteristic costant across time (this is why there is only "i" and not "t" associated to this term). Therefore, the assumptions behind the Pooled OLS to have a consistent estimator are:

- Contemporaneous Exogeneity 
\begin{align*}
Cov(x_{it},\epsilon_{it})= 0 \quad \text{with} \quad t=1,...,T
\end{align*}

- and Uncorrelated Effects
\begin{align*}
Cov(x_{it},\alpha_{i})= 0 \quad \text{with} \quad t=1,...,T
\end{align*}

In this context the uncorrelated effects assumption is not likely to be satisfided. For instance, factors such as the average distance from working place can be correlated with the number of cars a family ownes. Given that in an average family with 3 membes, 2 of them are working far away from home, it is more likely that they will own more than a car. Other causes of endogeinty can be: how developed the public transportation network is or how strong is the driving culture in a country. Given a country with a well developed public transportation system, the sensibility of people for increases in gasoline price will be high. On the other hand, given a strong car driving culture, the sensibility of people for increases in gasoline price will be low. Since the assumptions are not likely to be fulfilled, the OLS estimator will be biased.

### (d) 
Truth:    
\begin{align*}
y = X\beta + (\gamma)\alpha + \epsilon
\end{align*}


Paper estimate:    
\begin{align*}
y = X\beta + \epsilon 
\end{align*}

Thus,

\begin{align*}
E(\hat\beta) &= \beta + \gamma(X'X)^{-1}X'\alpha \\
&= \beta + \gamma \hat{\beta_{\alpha-on-X}}
\end{align*}

Where $\gamma$ is the (implicit) sign of impact of $\alpha_i$ on $y_i$ and $\hat\beta_{\alpha-on-X}$ measures the correlation between $\alpha_i$ and $x_i$
The direction can be both positive and negative depending on the OVB we analize. 

1. Negative bias
In case the unobserved factor is how well developed public transportation network is in a country: 

- $\gamma$ will be negative -> the more developed the network is, the less people will use the car and also less will be the consumption of gasoline
- $\hat\beta_{\alpha-on-X}$ will be positive -> an increase in gasoline price will result in more people using the public transportation, so higher revenues for public transportation companies. They will invest more in the development of the network, leading to an increase in a better developed public transportation network. 

2. Positive bias
In case the unobserved factor is how strong the driving culture in a country:

- $\gamma$ will be positive -> the stronger the driving culture, the more people will drive, the more the consume in gasoline per car
- $\hat\beta_{\alpha-on-X}$ will be positive -> the stronger the driving culture, the more people will drive. This leads to an higher demand for gasoline which will raise the price of the gasoline. 

###(e)
####(e.i) The LSDV EStimator
```{r}
# LSDV Model
lsdv.model <- lm(c ~ y+p+car + as.factor(co), data=pdata, na.action=na.omit)
```
####(e.ii) Fixed Effects
```{r}
# Fixed effects or within estimator
fixed <- plm(c ~ y+p+car, data=pdata, model= "within")
```
####(e.iii) Random Effects
```{r}
# Random effects estimator
random <- plm(c ~ y+p+car, data=pdata, model= "random")
```

```{r}
stargazer(pooling, lsdv.model,fixed, random, type="text", title="Comparison of Results",
          dep.var.labels=c("Gas per car consumption"),
          covariate.labels=c("Per capita income", "Gasoline price","Cars per capita"), align=TRUE)
```


```{r, include=FALSE}

# Between estimator
between <- plm(c ~ y+p+car, data=pdata, model= "between")
summary(between)

# First differences estimator
firstdiff <- plm(c ~ y+p+car, data=pdata, model= "fd")
summary(firstdiff)

# Fixed effects or within estimator
fixed <- plm(c ~ y+p+car, data=pdata, model= "within")
summary(fixed)

# Random effects estimator
random <- plm(c ~ y+p+car, data=pdata, model= "random")
summary(random)

# LM test for random effects versus OLS
plmtest(pooling)

# LM test for fixed effects versus OLS
pFtest(fixed, pooling)

# Hausman test for fixed versus random effects model
phtest(random, fixed)

# LSDV Model
lsdv.model <- lm(c ~ y+p+car + as.factor(co), data=pdata, na.action=na.omit)
summary(lsdv.model)


stargazer(pooling, lsdv.model,fixed, type="text", title="Pooled OLS Results",
          dep.var.labels=c("Gas per car consumption"),
          covariate.labels=c("Per capita income", "Gasoline price","Cars per capita"), align=TRUE)
```

